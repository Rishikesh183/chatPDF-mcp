# ğŸ§  Agentic RAG Chatbot with MCP (LangGraph + LangChain)

This project is a **Retrieval-Augmented Generation (RAG)** chatbot that answers user queries using uploaded documents. It is built with an **agentic architecture** using LangGraph and follows a custom **Model Context Protocol (MCP)** to simulate inter-agent communication.

---

## ğŸš€ Features

- âœ… **Multi-format document ingestion** (`PDF`, `PPTX`, `DOCX`, `CSV`, `TXT`, `MD`)
- ğŸ§  **Three-Agent Architecture**:
  - `IngestionAgent`: Parses and splits documents
  - `RetrievalAgent`: Embeds + semantically searches relevant chunks
  - `LLMResponseAgent`: Builds prompt and generates final answer
- ğŸ”— **MCP (Model Context Protocol)** message-passing system
- ğŸ§© Powered by `LangGraph`, `LangChain`, `FAISS`, `Google Gemini / OpenAI`
- ğŸŒ **Streamlit UI** for uploads and multi-turn Q&A

---

## ğŸ§± Tech Stack

| Layer        | Tool                              |
|--------------|-----------------------------------|
| LLM          | Gemini 2.0 Flash / OpenAI         |
| Embeddings   | HuggingFace / OpenAI              |
| Vector DB    | FAISS                             |
| Framework    | LangChain + LangGraph             |
| UI           | Streamlit                         |
| Protocol     | Custom MCP (in-memory)            |

---

## ğŸ“ Project Structure

```
rag-chatbot/
â”‚
â”œâ”€â”€ main.py # LangGraph pipeline runner
â”œâ”€â”€ agents/ # All 3 agents
â”‚ â”œâ”€â”€ ingestion_agent.py
â”‚ â”œâ”€â”€ retrieval_agent.py
â”‚ â””â”€â”€ llm_response_agent.py
â”‚
â”œâ”€â”€ mcp/
â”‚ â””â”€â”€ protocol.py # MCPMessage + MessageBus
â”‚
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ loaders.py # Multi-format document loaders
â”‚
â”œâ”€â”€ data/uploaded_docs/ # File uploads (PDF, PPTX, etc.)
â”‚
â”œâ”€â”€ ui/
â”‚ â””â”€â”€ app.py # Streamlit UI
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ architecture.pptx # Slide deck for submission
```

---

## ğŸ› ï¸ Setup Instructions

### 1. ğŸ“¦ Install Dependencies

```bash
uv pip install -r requirements.txt ( if you are not using uv use `pip install -r requirements.txt` )
```

### 2. ğŸ”‘ Set API Keys

```
set up a .env file with GOOGLE_API_KEY="get your api key from "https://aistudio.google.com/app/apikey"
```

### 3.ğŸ–¥ï¸ Launch the UI

```bash
streamlit run app.py
```


